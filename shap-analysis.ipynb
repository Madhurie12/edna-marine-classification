{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11683481,"sourceType":"datasetVersion","datasetId":7332902}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.preprocessing import LabelEncoder\nfrom collections import Counter\n\n# df = pd.read_csv('your_data.csv')  # Replace with the correct path to your CSV file\n\n# Ensure the column names are correct by removing any extra spaces (if any)\ndf.columns = df.columns.str.strip()\n\n# Print column names to verify\nprint(\"Columns in dataset:\", df.columns)\n\n# Check if 'scientificName' column exists and use it as the target\nif 'scientificName' not in df.columns:\n    print(\"Error: 'scientificName' column not found in the dataset.\")\nelse:\n    # Assuming 'scientificName' is the target column in your dataset\n    X = df.drop(columns=['scientificName'])  # Features\n    y = df['scientificName']  # Target variable\n\n    # Display the number of samples in each class before SMOTE\n    print(\"Original class distribution:\", Counter(y))\n\n    # Optionally, filter out classes with fewer than 3 samples if they are too rare\n    min_class_size = 3  # Threshold for minimum samples in each class\n    y_counts = y.value_counts()\n    valid_classes = y_counts[y_counts >= min_class_size].index\n\n    # Filter the dataset to only include these valid classes\n    X_filtered = X[y.isin(valid_classes)]\n    y_filtered = y[y.isin(valid_classes)]\n\n    # Remove non-numeric columns for model training (e.g., identifiers, textual columns)\n    X_filtered = X_filtered.select_dtypes(include=['number'])  # Only keep numeric columns\n\n    # Handle categorical features (if any)\n    # Encode categorical features using LabelEncoder\n    categorical_cols = X_filtered.select_dtypes(include=['object']).columns\n    le = LabelEncoder()\n\n    for col in categorical_cols:\n        X_filtered[col] = le.fit_transform(X_filtered[col].astype(str))\n\n    # Handle class imbalance using SMOTE with adjusted n_neighbors\n    smote = SMOTE(random_state=42, k_neighbors=2)  # Decrease k_neighbors to 2 for small classes\n    X_res, y_res = smote.fit_resample(X_filtered, y_filtered)\n\n    # Display the class distribution after SMOTE\n    print(\"Resampled class distribution:\", Counter(y_res))\n\n    # Compute class weights for the resampled data\n    class_weights = compute_class_weight('balanced', classes=y_res.unique(), y=y_res)\n    class_weight_dict = dict(zip(y_res.unique(), class_weights))\n\n    # Train a model, e.g., RandomForestClassifier, with cross-validation\n    clf = RandomForestClassifier(class_weight='balanced', random_state=42)\n\n    # Perform cross-validation\n    cross_val_scores = cross_val_score(clf, X_res, y_res, cv=5)\n\n    # Print cross-validation accuracy scores\n    print(f\"Cross-validation accuracy scores: {cross_val_scores}\")\n    print(f\"Mean cross-validation accuracy: {cross_val_scores.mean()}\")\n\n    # Train the classifier on the entire resampled dataset and generate predictions\n    clf.fit(X_res, y_res)\n\n    # Predict on the resampled data\n    y_pred = clf.predict(X_res)\n\n    # Generate a classification report\n    print(\"Classification Report:\")\n    print(classification_report(y_res, y_pred))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install shap","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Create a much taller figure to accommodate all class labels\nplt.figure(figsize=(10, 16))  # Increase height significantly\n\n# Create the SHAP summary plot\nshap.summary_plot(shap_values, X_res, plot_type=\"bar\", show=False)\n\n# Get the legend and modify its properties\nleg = plt.gca().get_legend()\nif leg:\n    # Increase the vertical spacing between legend entries\n    leg.set_bbox_to_anchor((1.05, 1))  # Move legend further right\n    leg._ncol = 1  # Ensure only one column of legend items\n    \n    # Adjust the spacing between legend items\n    for t in leg.get_texts():\n        t.set_y(1.5 * t.get_position()[1])  # Increase vertical spacing between text elements\n\n# Save with high resolution\nplt.savefig(\"shap_summary_plot.png\", dpi=300, bbox_inches=\"tight\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}